#+AUTHOR: Denis Davidoglu

* BLG 337E - Computer Communications
** Time & place
   - Monday 14:30-17:29, INB A205
** Contact
   - azaim@itu.edu.tr
** Course plan
   | Week | Topic                                                           |
   |------+-----------------------------------------------------------------|
   |    1 | Computer Networks and the Internet (Chapter_1_v8.1)             |
   |    2 | Protocol Concept and TCP/IP Protocol Stack (Traceroute Project) |
   |    3 | Application Protocols: Web, HTTP, FTP, etc. (Chapter_2_v8.1)    |
   |    4 | Application Protocols: Web, HTTP, FTP, etc.                     |
   |    5 | Transport Layer Protocols (Chapter_3_V6.0)                      |
   |    6 | Transport Layer Protocols                                       |
   |    7 | Midterm Exam                                                    |
   |    8 | Network Layer Protocols (Chapter_4_V6.0_1.ppt)                  |
   |    9 | Network Layer Protocols (Chapter_4_V6.0_2.ppt)                  |
   |   10 | Network Layer Protocols (Project Given in Class)                |
   |   11 | Data Link Layer Protocols (Chapter_5_V6.01)                     |
   |   12 | Data Link Layer Protocols                                       |
   |   13 | Wireless and Mobile Networks                                    |
   |   14 | Wireless and Mobile Networks                                    |

** Projects
   - [[file:projects/traceroute][Traceroute]]
** Textbook
   - [[file:docs/Computer Networking. A Top Down Approach, 7th.pdf][Computer Networking. A Top Down Approach.]]
** Notes
*** Week 3
**** Delay, Loss, and Throughput in Packet-Switched Networks
     - Internet is based on packet switch. Alternative name, store and forward.
     - Host -> router(xN) -> destination
     - Packets should be stored in router
     - Host divides a single long message into packets, because there is a certain capacity for transmission units.
     - Packets are transmitted independenty
     - Packet is divided into header and data. Router just looks at the header to find the destination IP. Then router decides where to send.
     - TCP/IP network
     - Destination point is responsible for reordering packets that arrived in arbitrary order.
     - While moving through each router, there are four types of delays:
       1. Transmission delay. Related to length of the packet and the transmission medium's limitation (bandwidth) (L bits)/ (R bits/second).
       2. Queueing delay. Packets are buffered and waiting for the outgoing link to become empty.
       3. Processing delay. Find packet, open header, decide outgoing link. Time spent inside CPU.
       4. Propagation delay. Time for a single bit signal to be transmitted. Depends on the physical characteristics on the link. Length (D). Transmission capacity, propagation speed of a signal (S). D/S.
     - Nodal delay: sum of all delays related to a router.
     - No overlapping between transmission and propagation delays.
**** Traceroute program. Project assignment. Write down a program call traceroute function to calculate minimum and maximum delays for different locations. Any programming language.
      1) Choose 10 locations going further apart from each other.
      2) From nearest to the furtherst.
      3) Repeat these measuremenets in 5 different days.
      4) Repeat in 3 different time.
      5) Repeat 100/200/300/1000 times.
      6) Tell about the feelings about end-to-end delays.
      7) Generate graph
      8) Don't give home address.
**** Application Layer
     - Application layer protocols. We write down software for hosts devices.
       1. Client-server approach paradigm
	  + Clients don't have permanent IP addresses.
	  + Servers are always on and have permanent IP addresses.
	  + Client is the process who initiates the communication.
	  + Server is the process waiting for service.
       2. Peer-to-peer approach paradigm
	  + Arbitrary systems, end devices directly connect without a server.
	  + Self-scalable network
	  + Ad-hoc
	  + Not designed previously
	  + Torrent
	  + Uses client-service paradigm. If downloading, it is client. If providing, server.
	  + In the same device, there can be both client and server processes at the same time.
     - Notion of process: program running within a host.
     - Either processors can comunicate on the same host or different hosts. Processors are the ones who communicate. Process communication by exchanging messages.
     - If running on the same device, it is called inter-process communication.
     - In the beginning, there is a client-server paradigm to connect clients. Afterwards, communication is peer-to-peer.
     - Types of messages
       + Syntax
       + Semantics
       + Rules of message exchanges. HTTP file transmission.
     - Application layer protocol requests from Transport layer:
       + Data integrity. Should providing service guaranteeing transmission form source to destination. Reliability.
       + Timing. Minimize delay.
       + Security.
       + Throughput. Transmit without dividing into small packets.
     - TCP/IP designed in 1969, therefore no security in the design philosophy.
     - With the came of online shopping, distributed versions started dealing with security. Each layer layer assumed security, but no separate layer for security.
     - Elastic applications, throughput
     - TCP protocol: data integrity
       + File transfers doesn't care about throughput, time sensitivity, but cares about data integrity.
     - UDP protocol: speed
       + Streaming is loss-tolerant, but has throughput and time sensitivity, with a minimum bandwidth.
**** Web & HTTP protocol
     - Web pages consists of object of different formats.
     - Base HTML file and connected objects.
     - Host: *www.someschool.edu/* somedir/x.html
     - Dir(path): www.someschool.edu/ *somedir/x.html*
     - To download from server to client, HTTP protocol is used. Web browser's application protocol.
     - TCP protocol is used as a transport layer for data integrity
     - Before transmission, TCP communication is initiated.
     - Client: TCP Request
     - Server: TCP Connect
     - Client: HTTP Request
     - Server: HTTP Response
     - TCP connection close
     - Connection-oriented communication model. In order to tranport a message, a connection is needed.
     - Setup - transfer - close. Reliable.
     - HTTP is a stateless protocol. The history of the communication information is not kept. Every new connection is not related to previous connections.
     - Persistent HTTP
       + TCP connection is created, all objects are downloaded, and then connections is closed. More efficient.
     - Non-persistent HTTP
       + Make TCP, download first index.html, close. Repeats many times. HTTP 1.0.
     - HTTP is stateless. Cookies introduce states. In classical Cookies, all requests are independently handled.
       1. Cookie Header Line (HTTP Response message). Should be added into the first message after request.
       2. Cookie header line next html request.
       3. Cookie file kept on the user's browser
       4. Backend database on the server side
     - Assume client is reaching server for the first time, making HTTP request.
       + Site sees the client for the first time and creates a record in its database
       + Client receives the response with cookie information.
       + A week later, client made another connection. The request contains cookie information in the header file now.
       + Server recognizes the client.
       + What if cookie is altered? Does the server ban you?
**** Web Caches (Proxy servers)
     - Speeding up the connection by caching data.
     - Keep and copy in local environment
     - To increase speed in a bottleneck, the easiest solution is to invest into new infrastructure to increase capacity.
     - Better solution is to install a proxy server. Around 40% of request can be found inside the local proxy server. Drastic improvement.
     - Proxy is not set by a provider
     - Caches must be refreshed
**** HTTP/2
     - Multiple pipeline operations
     - Requests are sent without waiting the responses
     - Automatic repeat request approach
     - Full bandwidth can be used for as much requests as needed
**** HTTP/3
     - Adding security per object error control and congestion control mechanics
     - Can choose between UDP and TCP
**** Email systems
     1) User agents.
	+ Example: Outlook
	+ Sends messages to server
	+ SMTP protocol between user and local server, as well as between servers
     2) Mail servers
     3) SMTP simple mail transfer protocol. Outlook.
	- Not the single approach.
	- Mail access protocols
	- IMAP - internet message access protocol. Used by webmail environments.
	- HTTP based protocols. Gmail, hotmail.
**** DNS - Distributed Database System?
     - Yellow pages for internet
     - Companies where posting their IP address
     - Difficult to reach
     - Application layer protocol
     - Related or implemented into the core internet functionality
     - IP addresses work on the middle, network layer. But we are dealing with it on application level.
     - Isn't this a dilemma for you?
     - Host aliasing function
     - Load balancing function
     - Works in a hierarchical and distribited manner
     - Top level DNS servers (tr, com)
     - Authoritative DNS servers (itu.edu.tr, amazon.com)
     - 300 server in USA
     - DNS name resolution is handled in two ways:
       1. Iterative.
	  + First request from local DNS server.
	  + If doesn't know, looks at the root DNS server.
	  + Pushes towards top-level domain server
	  + Client keeps the information
       2. Recursive
	  + Local DNS
	  + Root DNS. Gets responsibility on its own and asks for the top-level domain.
	  + Check for the authoritative DNS
	  + Everything sent back. Authortitative - TLD - Root - Local DNS - host
     - We don't want to put burden on the root DNS, recursive not commonly used
**** P2P architectures - next week.
*** Week 4
**** So far, client-server protocols have been discussed
**** P2P network
     - Does not require any server
     - Arbitrary devices can communicate directly
     - Adhoc network
     - Network is based on the number of the self-scalable devices
     - Example: SKype, Bittorrent
**** File distribution: client-server vs p2p
     - Distributing a file from many clients
     - Client server example:
       + File of size F and N peers downloading
       + They have a certain limited upload/download capacities
       + D_{c-s} >= max{N*F/u_s, F/d_min}. Time to distribute F to N clients using client-server approach
       + Server upload capacity = u_s.
       + d_min = bottle-neck speed of download on the client side
       + Increases linearly depending on N.
     - P2P:
       + Each client keeps a copy or a part of the file
       + D_P2P >= max{F/u_s, F/d_min, NF/(u_s + SUM(u_i))}
       + Uploading the file to the network, F/u_s
       + Each client keeps a copy, F/d_min
       + If we keep a copy of the file among many users, N*F bits will be distributed across clients. Can take either u_s, copy from server, or SUM(u_i), from all clients.
     - Increases on average logarithmically depending on N, eventually becoming stable.
**** Example BitTorrent
     - Ethical perspective, when using torrent file sharing programs. Professor explains how to desing such a network, but does not recommend sharing illegal and copyrighted materials.
     - The file is divided into small portions of subfiles, called *chunks*. Size of 256 Kbits.
     - Torrent: group of peers exchanging chunks.
     - At the beginning, a tracker tracks peers participating in torrent. Finds a list of peers active, who have chunks of that file.
     - Peer joining torrent. Has no chunks, but will accumulate from other peers over time
     - While downloading, a peer is also uploading to other peers
     - Once peer finishes downloading, they can selfighly leave or altruistically remain on torrent
**** Example: pirating the "Led Zeppelin" album
     - Px - peer, |x| chunk available
     - P1: |1|3|4|7|
     - P2: |2|5|6|
     - P3: |8|9|
     - P4: |10|
     - P5: |2|3|4|
     - P6: |1|9|10|
     - Chunk 1 has two copies, 10 has two copies
     - Rarest available chunks are downloaded as fast as possible, because peers can leave
     - Rarest-first algorithm
     - Sending chunks:
       + tit-for-tat agreement.
       + Choose peers based on their trasfer rate (bandwidth), if there are multiple sources of the same chunk available, or multiple peers request the same chunks.
       + Reevaluate every top peers every 4 seconds, assuming better services would be provided by others
     - Top-four providers are situated on the bottlenecks
     - Tracker keeps and updates the list
**** Question, when was P2P invented?
     - P2P for file sharing was first developed in the 1990's, but in the 2000's became popular
**** Video streaming and CDNs:
     - stream video traffic consumes 80% of the residential ISP traffic (2020 data)
     - Example: Netflix, YouTube, Amazon Prime
     - Challange: how to reach ~1 billion users
     - Challange: heterogenety
       + Different users have differnet capabilies (computers, mobile phones)
     - Solution: distributed application level infrastructre
**** Multimedia: video
     - video: sequence of images displayed at constant rate
     - spatial coding example: instead of sending N values of cam ecolor, send only two values: the color and duration
     - temporal coding example: instead of sending complete frame at i+1, send only differences from frame i.
     - Bit rate affects the bandwidth.
     - CBR (contant bit rate) for voice, VBR (variable bit rate) for video.
     - Available bit rate, internet.
     - MPEG 4 bandwidth
**** Streaming stored video
     - Challanges of server-client approach.
       + Internet is random, speed is always different
       + Packet loss and delay due to congestion will delay playout or result in poor video quality
     - Cummulative data will increase as time passes. Video recording delay, network delay, video receiving delay.
     - jitter - delay variation
     - If network delay is constant, we can store images in a buffer
     - But network is not constnat, buffer can become empty and client doesn't receive anything
     - Once playback beings, client-side buffer should mach playout requirement
     - Client interactivity: Pause, fast-forwars, rewind, jump.
**** Streaming multipedia: DASH
     - Dynamic Adaptive Streaming over HTTP.
     - server
       + divides video into multple chunks
       + Each chunk sotred, encoded at different rates
       + manifest file: provides urls for different chunk
     - client
       + periodically measures server-to-cient bandwidth
     - Intelligence in client:
       - when to request chunk
       - what encoding rate
       - where to request chunk
     - Streaming video = encoding + DASH + playout buffering
**** Content distribution networks (CDN)
     - Challange: how to steram content  seelctom form milions of videos to hundreds of thousands simultaneous users
     - Solution 1: Large mega server
       + single point of failure
       + point of network congestion
       + long path to distant client
       + multiple copies of video sent over outgoinl king
       + This solution doens't scale
     - Solutuion 2: store/sever multiple copies of vidoes at multiple geographically distributed sytes (CDN)
       + enter deep: push cdn dervers into many access networks
       + bring home
     - CDN stores copies contnet at CDN nodes
     - subscriber requests content from CDN
       + directed to nearby copy, retrieves copeis
       + may choose different copy if network path congested
     - Over the top services: coping with a congested internet
       + from which cdn node to retrieve
       + ???
       + what content to place on the cdn node
     - Example with BOB (client)
       1. Video requested
       2. Resolve address via local DNS
       3. Authoritative DNS will answer to BOB with the ip address of the CDN server, content provider
     - Netflix
       1. BOB manages Netflix accout
       2. Search netflix video
       3. Manifest file requested returned for specific video
       4. DASH server is contacted and streaming begins
     - The file is obtained as a whole, not chunks. But similar to the P2P approach of the BitTorrent.
     - Many CDN servers instead of peers
**** HOMEWORK UPDATE
     - 4 days/ up to 100 traceroute calls
     - Next week new project will be annoucned. Client and socket program.
     - STILL EASYY
     - 6th of November midterm (/hopefully/)
**** Transport layer protocols
     - Purpose: multiplexing, demultiplexing, reliable data transfer
     - Deals with the flow control mechanisms
     - Flow control
     - Congestion control
     - TCP as the first example
**** Trasnport services and protocols
     - Provides logical communciation between application processes nd running on differnet hosts
     - Transport protocols
       + On sender side: breaks information to packets
       + On receiver side: reassebmles information
     - Household analogy:
       + 12 kids in Ann's house sending letters to 12 kids in Bill's house
       + hosts = houses
       + processes = kids
       + app mesages = letters in envelopes
       + What is the role of the trasport layer?
       + Keeping integrity of the messages
       + In the analogy, transport layer = envelopes (make sure messages are delivered to the right location)
       + Which one is the network layer?
       + Network layer = postal service. Transferring messages from A to B.
       + Link layer = router or in analogy plane, bike, post box
       + Similar questions on midterm, making analogies
       + Divide and conquer reference
       + Understand the philosophy!
**** Transport layer actions
     - Message given to the transport layer, which appends a transport layer segment
**** Two protocols: TCP, UDP
**** Multiplexing and demultiplexing skipped
**** Summary of the transport layer
     - Mux demux happens at all layers
**** UDP: User Datagram Protocol
     - no frills, bare bones protocol
     - out of order delivery
     - connectionless transmission
     - no setup
     - small header size
     - Usage: DNS, SNMP, HTTP/3
     - UDP segment generated and transferred directly to IP
     - Cheksum header value for error control
     - Segment header:
       + source port
       + dest port
       + length,
       + checksum
       + application data (payload)
     - UPD checksum
       + detect flipped bits in transmitted segment.
       + 5, 6 trasmitted, 11 sum, 11 checksum.
       + 4, 6 trasmitted, 10 sum, 11 checksum.
**** Internet checksum
     - addition one's complement sum of segment content.
     - example
       + Carry wraps around, added to the least significant bit
       + Be sure that this will be on midterm
       + Documents can be brought to exam.
       + Don't bring this: https://github.com/dawidogg/5th-Semester-Notes/blob/main/Computer%20Communications/cc_notes.org
       + No sharing of documents during the exam
**** Principles of reliable data transfer
     - Reliable data tranfer protocol (rdt): interfaces
       + rdt_send(). Provides data through a port through transport layer protocol. TLP provides message to an unreliable channel.
       + udt_send(). Unreliable data send? Push message based on the data from app layer
       + rdt_rcv(). Receive from unreliable data channel. Check for errors. If correct, deliver to the receiver of the communication.
       + Remove some data portion and pass.
       + deliver_data(). Called by rdt to deliver data to the upper layer
     - Start defining protocols based on extended finite state machines (FSMs).
**** rdt1.0 protocol. perfect case.
      - assumtion taht underlying channel is perfectly reliable.
      - separate FSMs for sender, receiver.
      - We create a packet and rdt_send(data) is triggered by incoming data.
      - During transaction, packet = make_pkt(data); udt_send(packet).
      - Send message through channel
      - We didn't add any extra value like sumcheck, because we know the channel is safe
      - On the receiver side, rdt_rcv(packet) listens the channel.
      - When receive event triggered, extract(packet data), deliver_data(data)
****  rdt2.0. introduce errors.
      - add bit errors after channel transmission, no packet loss
      - to recover from errors (stop and wait protocols category):
	1. acknowledgments (ACKs). Message that packet received without error. Tell to procceed to other packets.
	2. negative acknowledgment (NAKs). Message that there has been an error. Resend.
      - FSM specification - Sender
	1. wait for call from above state.
	2. wait for ACK or NAK
      - FSM - Receiver
	- wait for call ??
      - Does not count for the corruption of acknowledgment/nacknowledgment
      - Solution: count the id numbers of the packet and track duplicated
**** rdt2.1.
     - Introduce a parity bit.
     - Sender:
       + Wait for call 0 from above.
       + Wait for ACK 0. If bit not matched.
       + Wait for call 1 from above.
       + Wait for ACK 1.
     - Receiver
       + Wait for 0 from below
       + Wait for 1 from below
**** rdt2.2 a NAK-free protocol
     - Sending positive and negative acknowledgment is harming performance
     - Send only the positive acknowledgment
     - Same functionality as rdt2.1
     - Receiver must include
     - Sender
       + Wait call 0 from above
       + Wait for ACK 0
     - Receiver
       + If wrong sequence number, either corrupt or not expected. Resend the message.
       + If the message has right sequence number and is not corrupt,
       + Wait 0 from below
**** rdt3.0 next week
*** Week 5
**** Reliable data trasfer - rdt3.0
	 - Move towards TCP protocol
	 - Channel can also lose packets (data, ACKs)
	 - In order to recover, new information is added (checksum, sequence, ACKs retransmission mechanisms)
	 - Sender wait a time before retransmitting a packet, if no ACK is received.
	 - There can be duplicates, but they have a sequence numbers
	 - "Reasonable amount of time", assumption
	 - Two sequnce numbers are enough because the system is stop-and-wait
	 - Sliding window if multiple packets are transmitted without waiting acknowledgments, more sequence numbers are introduced
	 - start_timer, stop_timer, timeout (triggers resend) in the FSM.
	 - Wrong sequence number acknowledgments are ignored
	 - If acknowledgment was not received, due to packet loss or acknowledgmentloss, either way the packet is resent.
	 - Premature timeout / delayed ACK. Nothing scary if acknowledgment sequence are coming wrong, because the out of sequence acknowledgments are ignored.
	 - t = RTT + L/R seconds for round-trip time and redistribution period. RTT = round-trip-time. L/R = file transfer time.
	 - U_sender = L/R / (RTT + L/R). Utilization of the system: actively used amount of time, fraction of time sender busy sending.
	 - Only L/R is the active tranmission time, (RTT + L/R) is the propagation time.
	 - rdt 3.0 protocol performance *stinks*, performance limited.
**** rdt3.0: sliding window protocol operation (pipelining)
	 - Push packets without waiting the acknowledgments
	 - U_sender = x*(L/R) / (RTT + L/R), send x packets one after the other
	 - X is up to 16, 30, depending on the congestion level
**** Go-Back-N in action
	 - Automatic Repeat reQuest protocols (ARQ)
	 - TCP is ARQ, using Go-Back-N, defacto flow control mechanism
	 - The sliding window size (buffer) is agreed before communication
	 - No more than window size amount of packets are sent before getting an acknowledgment
	 - Whenever acknowledgment is received, window slides
	 - Cummulative ACK. Acknowledgments for packets with higher order are not sent before the acknowledgments of lower packets.
	 - N is the erroneous packet number.
	 - When duplicate ACK is received, there is an error. All packets in the window, starting from the first erroneous packet are resent.
	 - Receiving out of order packet or timeout causes duplicate acknowledgment to be sent.
**** Connection-oriented transport: TCP
	 - Three-way handshake was: welcome setup, acknowledgement, setup
	 - Two-army problem. B W B. Total forces of blue armies are enough to defeat white army. But when separate, not enough. The only way of communicating between two armies is to send someone. How many soldiers are needed? /That's a good exam question/.
	 - We just hope 3 are enough. Not guarantee, but prevents from losing time.
	 - Point-to-point
	 - Reliable
	 - Cumulative ACKs
	 - Full duplex data
	 - Pipelining
	 - Connection-oriented
	 - Flow controlled
	 - Segment structure
	   + Source port #, destination port # (gateway numbers)
	   + Sequence number (byte-count). Acknowledgment becomes the sequence number.
	   + Acknowledgment number are sequence numbers summed with the number of byte after each transmission.
	   + Length (of TCP header)
	   + Receive window
	   + Checksum
	   + Congestion notifications
	   + Acknowledgment bit (if using or not)
	   + Connection management bits for handshaking
	   + Application data
	 - Performance modeling is the focus of exam
	 - Exam is 1 hour, 3 questions
	 - Triple (duplicate) ACK. If the same ACK is received three times, the sender understands that a packet is lost.
**** Principles of congestion control
	 - Too many senders sending too fast
	 - Manifestations
	   + Long delays
	   + Packet losses
	 - TCP solves the congestions at the end devices
	 - Routeres can provide direct feedback about congestion, send explicit congestion info.
	 - TCP Additive Increase Multiplicative Decrease (AIMD)
	   + Sender can increase sending rate until there is packet loss
	   + Increase sending rate by 1
	   + Cut sending rate in half at each loss. Detected by triple duplicate ACK (TCP Reno).
	   + If due to timout, slow start phase. Cut to 1 MMS (maximum segment size). (TCP Tahoe).
**** TCP slow start
	 - Congestion window size (cwnd) = 1 MSS
	 - Double cwnd every RTT
	 - Done by incrementing cwnd for every ACK received
	 - From slow start to congestion avoidance. When should the exponential increase switch to linear. Answer: when cwnd gets to 1/2 of its value before timeout. There is a threshold value, after which we should be aware that the network can congest. After the threshold value, we go to congestion avoidance linear phase, instead of doubling the window. Even with Tahoe, the threshold goes to half, but slow start is still applied.
	   #+begin_quote
	   Bu soruyu SORACAM size.
	   #+end_quote
**** Triple ACK
	 - Reno - cwnd = 1/2 value, sshthreshold = cwnd (congestion avoidance)
	 - Tahoe - cwnd = 1mss,  sshthreshold = 1/2 current value (congestion avoidance)
	 - In case of timeout, both are like Tahoe.
	 - On a router, it is impossible to use application-layer protocols. Routers work on the third layer. There are router programs on the application-level, but they are not compliant with TCP/IP, and they shouldn't at all.
**** Appocalipse of two elephants
	 - Investements come before technology. If the gap between technology and investments increases, standards cannot be adopted.
	 - De-facto standard (TCP/IP), created by investers.
	 - De jure standard OSI, but not used.
	 - Technology came behind investments in computer communications.
	 - We use IPv4 routers due to large investments, although we have IPv6 for 20 years.
